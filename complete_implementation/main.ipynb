{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\PointNet\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from torch.utils import data\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Tuple, Dict\n",
    "import os\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the various characters in the transcripts of the datasetW\n",
    "VOCAB = ['<sos>',   \n",
    "         'A',   'B',    'C',    'D',    \n",
    "         'E',   'F',    'G',    'H',    \n",
    "         'I',   'J',    'K',    'L',       \n",
    "         'M',   'N',    'O',    'P',    \n",
    "         'Q',   'R',    'S',    'T', \n",
    "         'U',   'V',    'W',    'X', \n",
    "         'Y',   'Z',    \"'\",    ' ', \n",
    "         '<eos>']\n",
    "\n",
    "VOCAB_MAP = {VOCAB[i]:i for i in range(0, len(VOCAB))}\n",
    "\n",
    "SOS_TOKEN = VOCAB_MAP[\"<sos>\"]\n",
    "EOS_TOKEN = VOCAB_MAP[\"<eos>\"]\n",
    "\n",
    "BATCH_SIZE = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCDataset:\n",
    "    def __init__(self, data_path, vocab_map, val = False, cep_norm = True):\n",
    "        \"\"\"\n",
    "        Let's access the datapaths for the input and the labels in this sections \n",
    "        x: MFCC path\n",
    "        y: Transcripts \n",
    "\n",
    "        1) Load all the data a-priori in the init for faster training. \n",
    "        2) Cepstral normalization :  \n",
    "        \"\"\"\n",
    "        self.val = val\n",
    "        self.cep_norm = cep_norm \n",
    "        if self.val:\n",
    "            self.x =  str(data_path)+\"\\\\dev-clean\\\\mfcc\\\\*.npy\" \n",
    "            self.y =  str(data_path)+\"\\\\dev-clean\\\\transcript\\\\*.npy\"\n",
    "        else: \n",
    "            self.x = str(data_path)+\"\\\\train-clean-100\\\\mfcc\\\\*.npy\"\n",
    "            self.y = str(data_path)+\"\\\\train-clean-100\\\\transcript\\\\raw\\\\*.npy\"\n",
    "\n",
    "        self.mfcc_list = sorted(glob.glob(self.x))\n",
    "        self.transcript_list = sorted(glob.glob(self.y))\n",
    "        self.alphabets = vocab_map\n",
    "       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.mfcc_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        cepstral normalization performed here for higher SNR \n",
    "        \"\"\"\n",
    "\n",
    "        if self.val:\n",
    "            mf_temp = np.load(self.mfcc_list[index], allow_pickle= True)\n",
    "            tr_temp = np.load(self.transcript_list[index], allow_pickle= True)\n",
    "            tr_temp = [self.alphabets[ele] for ele in tr_temp]\n",
    "            if self.cep_norm:\n",
    "                mf_temp = (mf_temp - np.mean(mf_temp, axis = 0))/ np.std(mf_temp)\n",
    "            \n",
    "            return torch.tensor(mf_temp)\n",
    "        \n",
    "        else: \n",
    "            mf_temp = np.load(self.mfcc_list[index], allow_pickle= True)\n",
    "            tr_temp = np.load(self.transcript_list[index], allow_pickle= True)\n",
    "            \n",
    "            # Converting the alphabets in the labels to integers using the pre-defined map provided \n",
    "            tr_temp = [self.alphabets[ele] for ele in tr_temp]\n",
    "\n",
    "            if self.cep_norm:\n",
    "                mf_temp = (mf_temp - np.mean(mf_temp, axis = 0))/ np.std(mf_temp)\n",
    "            return torch.tensor(mf_temp), torch.tensor(tr_temp)\n",
    "\n",
    "#Collate function for uniform padding of the input sequences \n",
    "\n",
    "def collate_train_val(data): \n",
    "    \n",
    "    (xx, yy) = zip(*data)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx,batch_first=True)\n",
    "    yy_pad = pad_sequence(yy,batch_first=True)\n",
    "\n",
    "    x_lens = np.asarray(x_lens)\n",
    "    y_lens = np.asarray(y_lens)\n",
    "    # Some augmentation and masking here may help the network converge better. \n",
    "\n",
    "        \n",
    "    return xx_pad, yy_pad, torch.tensor(x_lens), torch.tensor(y_lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and dataloader sections \n",
    "data_path = \"C:\\\\Users\\\\thopa\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\11-785-f22-hw4p2\\\\hw4p2\"\n",
    "train_data = MFCCDataset(data_path, vocab_map= VOCAB_MAP)\n",
    "val_data = MFCCDataset(data_path,vocab_map= VOCAB_MAP, val = True)\n",
    "\n",
    "train_loader = DataLoader(train_data ,batch_size = 8 , collate_fn= collate_train_val , shuffle = True)\n",
    "val_loader = DataLoader(val_data,batch_size = 8, collate_fn = collate_train_val, shuffle= False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network and Training "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silly notes for reference \n",
    "When training RNN (LSTM or GRU or vanilla-RNN), it is difficult to batch the variable length sequences. For example: if the length of sequences in a size 8 batch is [4,6,8,5,4,3,7,8], you will pad all the sequences and that will result in 8 sequences of length 8. You would end up doing 64 computations (8x8), but you needed to do only 45 computations. Moreover, if you wanted to do something fancy like using a bidirectional-RNN, it would be harder to do batch computations just by padding and you might end up doing more computations than required.\n",
    "\n",
    "Instead, PyTorch allows us to pack the sequence, internally packed sequence is a tuple of two lists. One contains the elements of sequences. Elements are interleaved by time steps (see example below) and other contains the size of each sequence the batch size at each step. This is helpful in recovering the actual sequences as well as telling RNN what is the batch size at each time step. This has been pointed by @Aerin. This can be passed to RNN and it will internally optimize the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PBLSTM,self).__init__()\n",
    "\n",
    "        self.blstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = 2, batch_first = True, bidirectional = True, dropout = 0.3)\n",
    "    \n",
    "    def reshape(self, x, x_lens):\n",
    "        # Reshaping for concatenation / reducing dimensions\n",
    "        batch, rows, cols = x.shape[0], x.shape[1], x.shape[2]\n",
    "\n",
    "        if (rows % 2 != 0):\n",
    "            x = x[:,:-1,:]\n",
    "        x = x.reshape(batch, int(rows/2), cols*2)\n",
    "        x_lens = x_lens//2\n",
    "    \n",
    "        return x, x_lens\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Computational savings and original sequence recovery using the pack padded and pad packed routine \n",
    "        \"\"\"\n",
    "        x_pad, x_pad_lens = pad_packed_sequence(x, batch_first=True)\n",
    "        x, x_lens = self.reshape(x_pad, x_pad_lens.to(\"cuda\"))\n",
    "        input = rnn_utils.pack_padded_sequence(x, lengths = x_lens.cpu(), batch_first= True, enforce_sorted= False)\n",
    "        rnn_out, _ = self.blstm(input)\n",
    "        #output, lens = rnn_utils.pad_packed_sequence(rnn_out, batch_first= True)\n",
    "        \n",
    "        return rnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, encoder_hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \"\"\"\n",
    "        The encoder used is a pyramidal-BiLSTM for matching the input rate and the speech transcription rate which is about 8:1. \n",
    "        This model is sigificantly influenced by the LAS paper \n",
    "        LAS: Chan, William, et al. \"Listen, attend and spell.\" arXiv preprint arXiv:1508.01211 (2015).\n",
    "\n",
    "        [REF: B. Raj, Deep Learning Carnegie Mellon University]\n",
    "        The pBLSTM is a variant of Bi-LSTMs that downsamples sequences by a factor of 2 by concatenating\n",
    "        adjacent pairs of inputs before running a conventional Bi-LSTM on the reduced-length sequence. So, given\n",
    "        an input vector sequence X0, X1, X2, X3, . . . XN−1, the pBLSTM first concatenates adjacent pairs of vectors\n",
    "        as [X0, X1], [X2, X3], . . . [XN−2, XN−1], and then computes a regular BiLSTM on the reshaped input.\n",
    "\n",
    "        -) Initial Bi-LSTM \n",
    "        -) 3x Pyramidal Bi-LSTM \n",
    "        \"\"\"    \n",
    "        self.base_lstm = nn.LSTM(input_size = input_size, hidden_size = encoder_hidden_size, num_layers = 1, batch_first = True, bidirectional = True, dropout = 0.1)\n",
    "        self.pblstm = nn.Sequential(PBLSTM(4*encoder_hidden_size,encoder_hidden_size),PBLSTM(4*encoder_hidden_size,encoder_hidden_size),PBLSTM(4*encoder_hidden_size,encoder_hidden_size))\n",
    "        \n",
    "    def forward(self, x, x_lens):\n",
    "        pack_padd_out = pack_padded_sequence(x, x_lens.to('cpu'),batch_first=True, enforce_sorted=False)\n",
    "        #print(type(pack_padd_out))\n",
    "        out_lstm, _  = self.base_lstm(pack_padd_out)\n",
    "        encoder_outputs = self.pblstm(out_lstm)\n",
    "        encoder_outputs, encoder_lens = pad_packed_sequence(encoder_outputs, batch_first=True)\n",
    "\n",
    "        return encoder_outputs, encoder_lens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummaryX import summary\n",
    "\n",
    "# for data in train_loader:\n",
    "#     x, y, lx, ly = data\n",
    "#     print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "#     break \n",
    "\n",
    "# encoder = Encoder(15,256)# TODO: Initialize Listener\n",
    "# out, lens = encoder.forward(x, lx)\n",
    "# del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention block \n",
    "\"\"\"\n",
    "Possible Efficiencies with the attention mechanism (d2l book)\n",
    "1) In general, it requires that both the query and the key have the \n",
    "same vector length, say d, even though this can be addressed easily by replacing \n",
    "q⊤k with q⊤Mk where M is a suitably chosen matrix to translate\n",
    "between both spaces. For now assume that the dimensions match.\n",
    "2) Adding dropout weights also helps \n",
    "\"\"\"\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_output_size, decoder_output_size, projection):\n",
    "        super(Attention, self).__init__()\n",
    "        self.key_layer = nn.Linear(encoder_output_size, projection)\n",
    "        self.value_layer = nn.Linear(encoder_output_size, projection)\n",
    "        self.query_layer = nn.Linear(decoder_output_size, projection)\n",
    "    \n",
    "    def key_value_calc(self, encoder_output, encoder_len):\n",
    "        _ ,encoder_max_seq_len, _ = encoder_output.shape \n",
    "        self.key = self.key_layer(encoder_output)\n",
    "        self.value = self.value_layer(encoder_output)\n",
    "        print(\"Attention Calculated\")\n",
    "        # Attention mask \n",
    "        # Removing the influence of padding in the raw weights, we create a boolean mask of (batchsize, timesteps)\n",
    "        self.mask = (torch.arange(encoder_max_seq_len)[None, :] < encoder_len[:, None]).to(\"cuda\")\n",
    "        \n",
    "    def forward(self, decoder_output_embeddings):\n",
    "        print(decoder_output_embeddings.shape)\n",
    "        self.query = self.query_layer(decoder_output_embeddings)\n",
    "        \n",
    "        energy = torch.bmm(self.key, self.query.unsqueeze(2))\n",
    "        \n",
    "        energy = torch.squeeze(energy, dim = 2)\n",
    "\n",
    "        #What should the mask least value be? \n",
    "        energy.masked_fill_(self.mask, -1e9)\n",
    "        \n",
    "        attention = torch.nn.functional.softmax(energy, dim = 1)\n",
    "        context = torch.bmm(torch.permute(self.value,[0,2,1]),attention.unsqueeze(2)).squeeze(2)\n",
    "        return context, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder ~ according to the speller of the LAS paper \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, projection, vocab_size, decoder_hidden_size, decoder_output_size, encoder_output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "        This module is often used to store word embeddings and retrieve them using indices. \n",
    "        The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0 ).cuda()\n",
    "        self.lstm_cells = nn.Sequential(nn.LSTMCell(embed_dim + projection , decoder_hidden_size) , nn.LSTMCell(decoder_hidden_size , decoder_output_size))\n",
    "        self.vocab_size = vocab_size\n",
    "        self.attention = Attention(2*encoder_output_size , decoder_output_size, projection)\n",
    "        self.character_prob = nn.Linear(512, vocab_size)\n",
    "        self.device = \"cuda\"\n",
    "        \n",
    "    def forward(self, encoder_output, encoder_len, y = None, mode = \"train\", teacherForcingRate = 0.1, isGumbel = False ):\n",
    "       \n",
    "        # batch, key_seq_max_len, key_value_size = key.shape\n",
    "        batch, encoder_max_seq, _ = encoder_output.shape\n",
    "\n",
    "        # # Attention mask for making the system autoregressive \n",
    "        # mask = torch.arange(key_seq_max_len).unsqueeze(0)>=encoder_len.unsqueeze(1)\n",
    "        # mask = mask.to(self.device)\n",
    "\n",
    "        # List to store output attention plots \n",
    "        predictions, attention_plot = [], []\n",
    "        prediction = torch.full((batch,1), fill_value = 0 ,device= self.device)\n",
    "        \n",
    "        # Hidden states\n",
    "        hidden_states= [None]*len(self.lstm_cells)\n",
    "        self.attention.key_value_calc(encoder_output, encoder_len)\n",
    "        \n",
    "        context = self.attention.value[:,0,:]\n",
    "\n",
    "        if mode == \"train\":\n",
    "            max_len = y.shape[1]\n",
    "            char_embedding = self.embedding(y)\n",
    "        else: \n",
    "            max_len = 600\n",
    "\n",
    "        for i in range(max_len):\n",
    "            if mode == \"train\":\n",
    "                # Teacher Forcing regime ~ Assigned and picked randomly \n",
    "                teacher_forcing = True if random.random() > teacherForcingRate else False \n",
    "                if not teacher_forcing:\n",
    "                    if i != 0 : # use Gumbel noise to add noise to add variety to phoneme\n",
    "                        char_embed = torch.nn.functional.gumbel_softmax(prediction).mm(self.embedding.weight)\n",
    "                    else:\n",
    "                        char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "                else:\n",
    "                    if i == 0:\n",
    "                        char_embed = self.embedding(torch.zeros(batch, dtype = torch.long).fill_(VOCAB_MAP['<sos>']).to(self.device)) \n",
    "                    else: \n",
    "                        char_embed = char_embedding[:,i-1,:] # ground truth teacher forcing \n",
    "            # Validation mode \n",
    "            else: \n",
    "                if i == 0: \n",
    "                    char_embed = self.embedding(torch.zeros(batch, dtype = torch.long).fill_(VOCAB_MAP['<sos>']).to(self.device)) \n",
    "                else: \n",
    "                    char_embed = self.embedding(prediction.argmax(dim = -1)) # feed in the previous prediction as input \n",
    "            \n",
    "            # Input to the decoder (prev embedding + context from attention mechanism) \n",
    "            decoder_input_embedding = torch.cat([char_embed, context.squeeze(1)], dim = 1)\n",
    "           \n",
    "            for i in range(len(self.lstm_cells)):\n",
    "                # An LSTM Cell returns (h,c) -> h = hidden state, c = cell memory state\n",
    "                # Using 2 LSTM Cells is akin to a 2 layer LSTM looped through t timesteps \n",
    "                # The second LSTM Cell takes in the output hidden state of the first LSTM Cell (from the current timestep) as Input, along with the hidden and cell states of the cell from the previous timestep\n",
    "                hidden_states[i] = self.lstm_cells[i](decoder_input_embedding, hidden_states[i]) \n",
    "                decoder_input_embedding = hidden_states[i][0]\n",
    "\n",
    "            decoder_output_embedding = hidden_states[-1][0]\n",
    "            # What is the query? (same len as the key)\n",
    "            # Hidden state of the LSTM \n",
    "            # 8x768 and 128x30\n",
    "            # decoder_output_embeddings, mask\n",
    "            context, attention = self.attention(decoder_output_embedding)\n",
    "            attention_plot.append(attention[0].detach().cpu())\n",
    "            \n",
    "            output_context = torch.cat([self.attention.query, context], dim = 1)\n",
    "            prediction = self.character_prob(output_context)\n",
    "            predictions.append(prediction.unsqueeze(1))\n",
    "        attentions = torch.stack(attention_plot, dim = 0)\n",
    "        predictions = torch.cat(predictions, dim = 1 )\n",
    "\n",
    "        return predictions, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining the pipelines of the Seq2Seq model\n",
    "\"\"\"\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, encoder_hidden_size, vocab_size, embed_size, decoder_hidden_size, decoder_output_size, projection_size = 128 ):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \"\"\"\n",
    "        Parameters of each of the model classes \n",
    "        Encoder : input_size, encoder_hidden_size\n",
    "        Decoder : embed_dim, projection, vocab_size, decoder_hidden_size, decoder_output_size, encoder_output_size\n",
    "        \"\"\"\n",
    "\n",
    "        self.encoder =  Encoder(input_size = input_size, encoder_hidden_size = encoder_hidden_size)\n",
    "        #self.attention = Attention(encoder_output_size= 2*encoder_hidden_size, decoder_output_size=decoder_output_size, projection= projection_size)\n",
    "        self.decoder =  Decoder(embed_dim = embed_size, projection = projection_size, vocab_size = vocab_size, decoder_hidden_size = decoder_hidden_size, decoder_output_size=decoder_output_size,encoder_output_size = encoder_hidden_size)\n",
    "    def forward(self, x, x_lens, y = None, mode = \"none\"):\n",
    "        \n",
    "        encoder_outputs, encoder_lens = self.encoder(x, x_lens)\n",
    "        # encoder_output, key, value, encoder_len, y = None, mode = \"train\", teacherForcingRate = 0.1, isGumbel = False \n",
    "        predictions, attention_map = self.decoder(encoder_outputs, encoder_lens , y, mode = mode)\n",
    "\n",
    "        return predictions, attention_map \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\PointNet\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (base_lstm): LSTM(15, 512, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (pblstm): Sequential(\n",
       "      (0): PBLSTM(\n",
       "        (blstm): LSTM(2048, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      )\n",
       "      (1): PBLSTM(\n",
       "        (blstm): LSTM(2048, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      )\n",
       "      (2): PBLSTM(\n",
       "        (blstm): LSTM(2048, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(30, 512, padding_idx=0)\n",
       "    (lstm_cells): Sequential(\n",
       "      (0): LSTMCell(768, 512)\n",
       "      (1): LSTMCell(512, 128)\n",
       "    )\n",
       "    (attention): Attention(\n",
       "      (key_layer): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (value_layer): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (query_layer): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (character_prob): Linear(in_features=512, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model initialization \n",
    "\"\"\"\n",
    "DEVICE = \"cuda\"\n",
    "model  = Seq2Seq(input_size=15,encoder_hidden_size=512,vocab_size=len(VOCAB),\n",
    "            embed_size=512,decoder_hidden_size=512,decoder_output_size=128,projection_size=256)\n",
    "model.to(DEVICE)\n",
    "# print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters under consideration \n",
    "- Optimizer\n",
    "    - Learning Rate\n",
    "    - Weight Decay\n",
    "- Learning Rate Scheduler\n",
    "    - reduction \n",
    "- Loss function \n",
    "    - Reduction\n",
    "    - Factor \n",
    "    - Patience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = 2e-3, weight_decay = 5e-6 )\n",
    "criterion = nn.CrossEntropyLoss(reduction = \"none\")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.4, patience = 2)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thopa\\AppData\\Local\\Temp\\ipykernel_26340\\2177239868.py:14: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x_lens = x_lens//2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 190, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 210, 30]), label:torch.Size([8, 210])\n",
      "torch.Size([8, 214, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 275, 30]), label:torch.Size([8, 275])\n",
      "torch.Size([8, 196, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 255, 30]), label:torch.Size([8, 255])\n",
      "torch.Size([8, 191, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 249, 30]), label:torch.Size([8, 249])\n",
      "torch.Size([8, 210, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 239, 30]), label:torch.Size([8, 239])\n",
      "torch.Size([8, 208, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 286, 30]), label:torch.Size([8, 286])\n",
      "torch.Size([8, 198, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 234, 30]), label:torch.Size([8, 234])\n",
      "torch.Size([8, 187, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 215, 30]), label:torch.Size([8, 215])\n",
      "torch.Size([8, 199, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 238, 30]), label:torch.Size([8, 238])\n",
      "torch.Size([8, 200, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 254, 30]), label:torch.Size([8, 254])\n",
      "torch.Size([8, 198, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 244, 30]), label:torch.Size([8, 244])\n",
      "torch.Size([8, 209, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 249, 30]), label:torch.Size([8, 249])\n",
      "torch.Size([8, 197, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "prediction:torch.Size([8, 275, 30]), label:torch.Size([8, 275])\n",
      "torch.Size([8, 199, 1024])\n",
      "Attention Calculated\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m x, x_len, y, y_len \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(DEVICE), x_len, y\u001b[39m.\u001b[39mto(DEVICE), y_len\n\u001b[1;32m----> 8\u001b[0m pred, attn \u001b[39m=\u001b[39m model(x \u001b[39m=\u001b[39;49m x, x_lens \u001b[39m=\u001b[39;49m x_len, y \u001b[39m=\u001b[39;49m y, mode \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mprediction:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, label:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(pred\u001b[39m.\u001b[39mshape, y\u001b[39m.\u001b[39mshape))\n\u001b[0;32m     10\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PointNet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [10], line 20\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, x, x_lens, y, mode)\u001b[0m\n\u001b[0;32m     18\u001b[0m encoder_outputs, encoder_lens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x, x_lens)\n\u001b[0;32m     19\u001b[0m \u001b[39m# encoder_output, key, value, encoder_len, y = None, mode = \"train\", teacherForcingRate = 0.1, isGumbel = False \u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m predictions, attention_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(encoder_outputs, encoder_lens , y, mode \u001b[39m=\u001b[39;49m mode)\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m predictions, attention_map\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PointNet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [9], line 81\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, encoder_output, encoder_len, y, mode, teacherForcingRate, isGumbel)\u001b[0m\n\u001b[0;32m     76\u001b[0m decoder_output_embedding \u001b[39m=\u001b[39m hidden_states[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     77\u001b[0m \u001b[39m# What is the query? (same len as the key)\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m# Hidden state of the LSTM \u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m# 8x768 and 128x30\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m# decoder_output_embeddings, mask\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m context, attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(decoder_output_embedding)\n\u001b[0;32m     82\u001b[0m attention_plot\u001b[39m.\u001b[39mappend(attention[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m     84\u001b[0m output_context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention\u001b[39m.\u001b[39mquery, context], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PointNet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [8], line 38\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, decoder_output_embeddings)\u001b[0m\n\u001b[0;32m     35\u001b[0m energy\u001b[39m.\u001b[39mmasked_fill_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask, \u001b[39m-\u001b[39m\u001b[39m1e9\u001b[39m)\n\u001b[0;32m     37\u001b[0m attention \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(energy, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(torch\u001b[39m.\u001b[39;49mpermute(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue,[\u001b[39m0\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m1\u001b[39;49m]),attention\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m2\u001b[39;49m))\u001b[39m.\u001b[39msqueeze(\u001b[39m2\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m context, attention\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100 \n",
    "\n",
    "for epoch in range(epochs): \n",
    "    model.train()\n",
    "    for i,(x, y, x_len, y_len) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, x_len, y, y_len = x.to(DEVICE), x_len, y.to(DEVICE), y_len\n",
    "        pred, attn = model(x = x, x_lens = x_len, y = y, mode = \"train\")\n",
    "        print(\"prediction:{}, label:{}\".format(pred.shape, y.shape))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PointNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be71f7ebca6fc406e8f2b7eb97fc71d65ed284e191505e45141d8f3008802363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
