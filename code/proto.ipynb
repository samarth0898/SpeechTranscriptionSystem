{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from torch.utils import data\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Tuple, Dict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocess:\n",
    "    def __init__(self):\n",
    "        self.letter_list = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \n",
    "               'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ', '<eos>']\n",
    "    \n",
    "    def transform_letter_to_index(self, raw_transcript):\n",
    "        output = []\n",
    "        for transcript in raw_transcript:\n",
    "            temp = [self.letter_list.index(j) for j in transcript]\n",
    "            output.append(temp)\n",
    "        return output\n",
    "    \n",
    "\n",
    "    def create_dictionaries(self):\n",
    "        '''\n",
    "        Create dictionaries for letter2index and index2letter transformations\n",
    "        '''\n",
    "        numbers=np.arange(len(self.letter_list))\n",
    "        letter2index={self.letter_list[i]: numbers[i] for i in range(0, len(self.letter_list))} \n",
    "        index2letter={numbers[i]: self.letter_list[i] for i in range(0, len(self.letter_list))} \n",
    "        return letter2index, index2letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Points: 10000, Val Points 100\n"
     ]
    }
   ],
   "source": [
    "# Load TOY DATASET for attention map \n",
    "train_data = np.load(\"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\2021_ToySet\\\\train.npz\", allow_pickle=True, encoding='bytes')['data']\n",
    "dev_data = np.load(\"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\2021_ToySet\\\\dev.npz\",  allow_pickle=True, encoding='bytes')['data']\n",
    "\n",
    "# Load the training, validation raw text transcripts\n",
    "train_labels = np.load(\"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\2021_ToySet\\\\train_transcripts.npz\", allow_pickle=True,encoding='bytes')\n",
    "dev_labels = np.load(\"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\2021_ToySet\\\\dev_transcripts.npz\",  allow_pickle=True,encoding='bytes')\n",
    "\n",
    "textprocess= TextPreprocess()\n",
    "# Convert the raw text transcripts to indices \n",
    "train_labelIDX = textprocess.transform_letter_to_index(train_labels['data'])\n",
    "val_labelIDX =  textprocess.transform_letter_to_index(dev_labels['data'])\n",
    "\n",
    "print(\"Training Points: {}, Val Points {}\".format(len(train_labelIDX), len(val_labelIDX)))\n",
    "\n",
    "letter2index, index2letter = textprocess.create_dictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building attention map with toy dataset \n",
    "class MelVectorDataset(Dataset):\n",
    "    def __init__(self, X, Y, val = False):\n",
    "\n",
    "        # X : Mel Features , Y : Mel Labels \n",
    "        self.X, self.Y = X, Y \n",
    "        self.val = val\n",
    "    \n",
    "    def __len__(self):\n",
    "    \n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.val: \n",
    "            return torch.as_tensor(self.X[index])\n",
    "        else: \n",
    "            return torch.as_tensor(self.X[index]), torch.as_tensor(self.Y[index])\n",
    "\n",
    "#Collate function for uniform padding of the input sequences \n",
    "\n",
    "def collate_train_val(data): \n",
    "    \n",
    "    (xx, yy) = zip(*data)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx,batch_first=True)\n",
    "    yy_pad = pad_sequence(yy,batch_first=True)\n",
    "\n",
    "    x_lens = np.asarray(x_lens)\n",
    "    y_lens = np.asarray(y_lens)\n",
    "    # Some augmentation and masking here may help the network converge better. \n",
    "\n",
    "        \n",
    "    return xx_pad, yy_pad, torch.tensor(x_lens), torch.tensor(y_lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets for train and validation \n",
    "train_dataset = MelVectorDataset(train_data, train_labelIDX, val = False)\n",
    "val_dataset = MelVectorDataset(dev_data, val_labelIDX, val = True)\n",
    "\n",
    "\n",
    "# Dataloader with collate functionality\n",
    "train_loader = DataLoader(train_dataset, collate_fn= collate_train_val , batch_size= 64, shuffle= True)\n",
    "val_loader = DataLoader(val_dataset, collate_fn= collate_train_val, batch_size= 64, shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, key_value_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.BiLSTM = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, num_layers = 3, bidirectional = True)\n",
    "        self.key = nn.Linear(hidden_dim*2, key_value_size)\n",
    "        self.value = nn.Linear(hidden_dim*2, key_value_size)\n",
    "    \n",
    "    def forward(self, input, input_len):\n",
    "        \n",
    "        # To save the number of computations since we are padding zeros \n",
    "        input = rnn_utils.pack_padded_sequence(input, lengths = input_len.cpu(), batch_first= True, enforce_sorted= False)\n",
    "        rnn_out, _ = self.BiLSTM(input)\n",
    "        output, lens = rnn_utils.pad_packed_sequence(rnn_out, batch_first= True)\n",
    "        key = self.key(output)\n",
    "        value = self.value(output)\n",
    "        \n",
    "        return key, value, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention block \n",
    "\"\"\"\n",
    "Possible Efficiencies with the attention mechanism (d2l book)\n",
    "1) In general, it requires that both the query and the key have the \n",
    "same vector length, say d, even though this can be addressed easily by replacing \n",
    "q⊤k with q⊤Mk where M is a suitably chosen matrix to translate\n",
    "between both spaces. For now assume that the dimensions match.\n",
    "2) Adding dropout weights also helps \n",
    "\"\"\"\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "    \n",
    "    def forward(self, query, key, value, mask):\n",
    "        energy = torch.bmm(key, query.unsqueeze(2))\n",
    "        energy = torch.squeeze(energy, dim = 2)\n",
    "\n",
    "        #What should the mask least value be? \n",
    "        energy.masked_fill_(mask, -1e9)\n",
    "\n",
    "        attention = torch.nn.functional.softmax(energy, dim = 1)\n",
    "        context = torch.bmm(attention.unsqueeze(1), value)\n",
    "        \n",
    "        return context, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder ~ according to the speller of the LAS paper \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, key_value_size, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "        This module is often used to store word embeddings and retrieve them using indices. \n",
    "        The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0 ).cuda()\n",
    "        self.lstm1 = nn.LSTMCell(embed_dim + key_value_size , key_value_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.attention = Attention()\n",
    "        self.character_prob = nn.Linear(2*key_value_size, vocab_size)\n",
    "        self.key_value_size = key_value_size\n",
    "        self.device = \"cuda\"\n",
    "        \n",
    "    def forward(self, key, value, encoder_len, y = None, mode = \"train\", teacherForcingRate = 0.1, isGumbel = False ):\n",
    "        \n",
    "        batch, key_seq_max_len, key_value_size = key.shape\n",
    "\n",
    "\n",
    "        # Attention mask for making the system autoregressive \n",
    "        mask = torch.arange(key_seq_max_len).unsqueeze(0)>=encoder_len.unsqueeze(1)\n",
    "        mask = mask.to(self.device)\n",
    "\n",
    "        # List to store output attention plots \n",
    "        predictions, attention_plot = [], []\n",
    "        prediction = torch.full((batch,1), fill_value= 0 ,device= self.device)\n",
    "\n",
    "        # Hidden states\n",
    "        hidden_state= [None, None]\n",
    "        context = value[:,0,:]\n",
    "\n",
    "        if mode == \"train\":\n",
    "            max_len = y.shape[1]\n",
    "            char_embedding = self.embedding(y)\n",
    "        else: \n",
    "            max_len = 300\n",
    "\n",
    "        for i in range(max_len):\n",
    "            if mode == \"train\":\n",
    "                # Teacher Forcing regime ~ Assigned and picked randomly \n",
    "                teacher_forcing = True if random.random() > teacherForcingRate else False \n",
    "                if not teacher_forcing:\n",
    "                    if i != 0 : # use Gumbel noise to add noise to add variety to phoneme\n",
    "                        char_embed = torch.nn.functional.gumbel_softmax(prediction).mm(self.embedding.weight)\n",
    "                    else:\n",
    "                        char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "                else:\n",
    "                    if i == 0:\n",
    "                        char_embed = self.embedding(torch.zeros(batch, dtype = torch.long).fill_(letter2index['<sos>']).to(self.device)) \n",
    "                    else: \n",
    "                        char_embed = char_embedding[:,i-1,:] # ground truth teacher forcing \n",
    "            # Validation mode \n",
    "            else: \n",
    "                if i == 0: \n",
    "                    char_embed = self.embedding(torch.zeros(batch, dtype = torch.long).fill_(letter2index['<sos>']).to(self.device)) \n",
    "                else: \n",
    "                    char_embed = self.embedding(prediction.argmax(dim = -1)) # feed in the previous prediction as input \n",
    "            \n",
    "            # Input to the decoder (prev embedding + context from attention mechanism) \n",
    "            y_context = torch.cat([char_embed, context.squeeze(1)], dim = 1)\n",
    "            hidden_state[0] = self.lstm1(y_context, hidden_state[0])\n",
    "\n",
    "            # What is the query? (same len as the key)\n",
    "            # Hidden state of the LSTM \n",
    "            query = hidden_state[0][0]\n",
    "            context, attention = self.attention(query, key, value, mask)\n",
    "            attention_plot.append(attention[0].detach().cpu())\n",
    "\n",
    "            output_context = torch.cat([query, context.squeeze(1)], dim = 1)\n",
    "            prediction = self.character_prob(output_context)\n",
    "            predictions.append(prediction.unsqueeze(1))\n",
    "        attentions = torch.stack(attention_plot, dim = 0)\n",
    "        predictions = torch.cat(predictions, dim = 1 )\n",
    "\n",
    "        return predictions, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, encoder_hidden_dim, vocab_size, embed_dim, key_value_size = 128):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim = input_dim, hidden_dim = encoder_hidden_dim, key_value_size = key_value_size )\n",
    "        self.decoder = Decoder(vocab_size = vocab_size, embed_dim = embed_dim, key_value_size= key_value_size)\n",
    "    \n",
    "    def forward(self, x, x_len, y = None, mode = \"train\", isTrain = True):\n",
    "        key, value, encoder_len = self.encoder(x, x_len)\n",
    "        predictions, attentions = self.decoder(key, value, encoder_len, y, mode)\n",
    "\n",
    "        return predictions, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = Seq2Seq(input_dim = 40,vocab_size = 34, encoder_hidden_dim = 128, embed_dim = 128)\n",
    "model=seq2seq_model.cuda()\n",
    "\n",
    "# Some other hyperparameter \n",
    "optimizer = optim.Adam(model.parameters(), lr= 2e-3)\n",
    "\n",
    "\"\"\"\n",
    "This criterion computes the cross entropy loss between input logits and target.\n",
    "\n",
    "It is useful when training a classification problem with C classes. \n",
    "If provided, the optional argument weight should be a 1D Tensor assigning weight to each of the classes. \n",
    "This is particularly useful when you have an unbalanced training set.\n",
    "\n",
    "\"\"\"\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Attention map plotting \n",
    "\n",
    "\"\"\"\n",
    "def plot_attention(attention, idx):\n",
    "    # utility function for debugging\n",
    "    path = \"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\code\\\\results\\\\\"\n",
    "    plt.clf()\n",
    "    sns.heatmap(attention, cmap='GnBu')\n",
    "    plt.savefig(\"{}_attn.png\".format(path + idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thopa\\AppData\\Local\\Temp\\ipykernel_24280\\3637603455.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_len = torch.max(torch.tensor(label_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/20] Training Loss: 3.2331273555755615\n",
      "Epoch[1/20] Training Loss: 3.2097597122192383\n",
      "Epoch[2/20] Training Loss: 3.2013869285583496\n",
      "Epoch[3/20] Training Loss: 3.1652865409851074\n",
      "Epoch[4/20] Training Loss: 2.9352993965148926\n",
      "Epoch[5/20] Training Loss: 2.557483673095703\n",
      "Epoch[6/20] Training Loss: 2.2713112831115723\n",
      "Epoch[7/20] Training Loss: 2.734706163406372\n",
      "Epoch[8/20] Training Loss: 2.70078706741333\n",
      "Epoch[9/20] Training Loss: 2.5099875926971436\n",
      "Epoch[10/20] Training Loss: 2.654869556427002\n",
      "Epoch[11/20] Training Loss: 2.8881139755249023\n",
      "Epoch[12/20] Training Loss: 3.0763747692108154\n",
      "Epoch[13/20] Training Loss: 2.839353561401367\n",
      "Epoch[14/20] Training Loss: 2.949983596801758\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [100], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, pred\u001b[39m.\u001b[39msize(\u001b[39m2\u001b[39m)), label\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     21\u001b[0m masked_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(loss \u001b[39m*\u001b[39m mask\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39msum(mask)\n\u001b[1;32m---> 23\u001b[0m masked_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     24\u001b[0m running_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mmasked_loss\n\u001b[0;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PointNet\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PointNet\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training sequence \n",
    "epochs = 20\n",
    "device = 'cuda'\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i,(data,label, data_len, label_len) in enumerate(train_loader):\n",
    "\n",
    "        # Avoid gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "        data, datalen, label, label_len = data.to(device), data_len, label.to(device), label_len\n",
    "        pred, attn = model(x = data, x_len = datalen, y = label, mode = \"train\")\n",
    "\n",
    "        # Dealing with masking and masking loss etc.\n",
    "        max_len = torch.max(torch.tensor(label_len))\n",
    "        lst = torch.arange(0,max_len).repeat(label_len.size(0),1)\n",
    "  \n",
    "        seq_len = label_len.unsqueeze(1).expand(label_len.size(0),max_len)\n",
    "        mask = (lst<seq_len).int().cuda() \n",
    "        loss = criterion(pred.view(-1, pred.size(2)), label.view(-1))\n",
    "        masked_loss = torch.sum(loss * mask.view(-1)) / torch.sum(mask)\n",
    "\n",
    "        masked_loss.backward()\n",
    "        running_loss+=masked_loss\n",
    "        optimizer.step()\n",
    "        idx = \"{}_{}\".format(epoch, i)\n",
    "        plot_attention(attn,idx)\n",
    "\n",
    "    print(\"Epoch[{}/{}] Training Loss: {}\".format(epoch, epochs, running_loss/len(train_loader)))\n",
    "    torch.save({'train_loss_history': running_loss,'optimizer_state_dict': optimizer.state_dict(), 'model_state_dict' : model.state_dict()}, os.path.join(\"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\code\\\\ckpt\", 'seq2seq_epoch_{}.pth'.format(epoch)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thopa\\AppData\\Local\\Temp\\ipykernel_24280\\3324046309.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(filename))\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import glob \n",
    "\n",
    "images = []\n",
    "filenames = \"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\code\\\\results\\\\*.png\"\n",
    "out = \"C:\\\\Users\\\\thopa\\\\Desktop\\\\Assignments\\\\11685\\\\HW4\\\\2022Implementation\\\\code\\\\gifs\\\\\"\n",
    "for filename in sorted(glob.glob(filenames)):\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('{}\\\\attention.gif'.format( out), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PointNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be71f7ebca6fc406e8f2b7eb97fc71d65ed284e191505e45141d8f3008802363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
